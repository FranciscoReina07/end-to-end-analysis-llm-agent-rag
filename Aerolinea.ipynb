{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "00b53022",
      "metadata": {},
      "source": [
        "# Proyecto Aerya: EDA, metricas, embeddings, agente y FastApi\n",
        "\n",
        "Objetivo:\n",
        "- EDA \n",
        "- Metricas de impacto para la aerolinea con scikit-learn.\n",
        "- Embeddings locales con Ollama.\n",
        "- Agente con LangGraph usando OpenAI (API).\n",
        "- End point con FastApi\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df0bc8f3",
      "metadata": {},
      "source": [
        "## 1. Configuracion y rutas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2bc221ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ENV CONFIG (primera celda)\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    raise ValueError(\"OPENAI_API_KEY no esta definida en .env\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "79e26884",
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_colwidth\", 120)\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
        "    force=True,\n",
        ")\n",
        "logger = logging.getLogger(\"aerya\")\n",
        "\n",
        "BASE_DIR = Path(\"data\")\n",
        "THREADS_PATH = BASE_DIR / \"Threads.json\"\n",
        "MESSAGES_PATH = BASE_DIR / \"Messages.json\"\n",
        "\n",
        "if not BASE_DIR.exists():\n",
        "    raise FileNotFoundError(f\"La carpeta de datos no existe: {BASE_DIR.resolve()}\")\n",
        "if not THREADS_PATH.exists() or not MESSAGES_PATH.exists():\n",
        "    raise FileNotFoundError(f\"Faltan archivos JSON en {BASE_DIR.resolve()}\")\n",
        "\n",
        "class DataValidationError(Exception):\n",
        "    pass\n",
        "\n",
        "class EmbeddingError(Exception):\n",
        "    pass\n",
        "\n",
        "class ModelTrainingError(Exception):\n",
        "    pass\n",
        "\n",
        "class AgentError(Exception):\n",
        "    pass\n",
        "def validar_columnas(df: pd.DataFrame, required: set[str], contexto: str) -> None:\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise DataValidationError(f\"Faltan columnas en {contexto}: {missing}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "469f2ed3",
      "metadata": {},
      "source": [
        "## 2. Carga y estructura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08d7b41e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:49:39,184 - aerya - INFO - Cargando datos desde data\\Threads.json y data\\Messages.json ...\n",
            "2026-02-09 14:49:52,483 - aerya - INFO - Datos cargados: threads=11500 filas, messages=135848 filas\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATAFRAME: df_threads\n",
            "Dimensiones: (11500, 41)\n",
            "\n",
            "Columnas\n",
            "['_id', 'thread_id', 'client', 'source', 'user', 'status', 'get_user_info', 'check_pnr', 'lookup_policy', 'availability', 'best_flight_option', 'booking', 'escalate_conversation', 'created_at', 'updated_at', 'check_flight_schedule', 'correlative_id', 'ai_resolved', 'ended_reason', 'flags', 'Checked_PNR', 'end_conversation', 'pnr', 'is_guest', 'email', 'last_tool_used', 'last_interaction_timestamp', 'checked_pnrs', 'cancel_purchase', 'Checked_pnrs', 'refund', 'check_in', 'escalated_at', 'escalation_summary', 'escalation_whatsapp_url', 'platform', 'comments', 'org_id', 'display_id', 'correlative_numeric', 'lookup_policy_count']\n",
            "\n",
            "Resumen de tipos y nulos\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11500 entries, 0 to 11499\n",
            "Data columns (total 41 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   _id                         11500 non-null  object \n",
            " 1   thread_id                   11500 non-null  object \n",
            " 2   client                      11500 non-null  object \n",
            " 3   source                      11500 non-null  object \n",
            " 4   user                        11500 non-null  object \n",
            " 5   status                      11500 non-null  object \n",
            " 6   get_user_info               11500 non-null  int64  \n",
            " 7   check_pnr                   11500 non-null  int64  \n",
            " 8   lookup_policy               11500 non-null  int64  \n",
            " 9   availability                11500 non-null  int64  \n",
            " 10  best_flight_option          11500 non-null  int64  \n",
            " 11  booking                     11500 non-null  int64  \n",
            " 12  escalate_conversation       11500 non-null  int64  \n",
            " 13  created_at                  11500 non-null  object \n",
            " 14  updated_at                  11500 non-null  object \n",
            " 15  check_flight_schedule       11498 non-null  float64\n",
            " 16  correlative_id              11500 non-null  object \n",
            " 17  ai_resolved                 11477 non-null  float64\n",
            " 18  ended_reason                11499 non-null  object \n",
            " 19  flags                       650 non-null    object \n",
            " 20  Checked_PNR                 22 non-null     object \n",
            " 21  end_conversation            716 non-null    float64\n",
            " 22  pnr                         11453 non-null  object \n",
            " 23  is_guest                    11453 non-null  float64\n",
            " 24  email                       11453 non-null  object \n",
            " 25  last_tool_used              9553 non-null   object \n",
            " 26  last_interaction_timestamp  10570 non-null  object \n",
            " 27  checked_pnrs                11316 non-null  object \n",
            " 28  cancel_purchase             11316 non-null  float64\n",
            " 29  Checked_pnrs                2530 non-null   object \n",
            " 30  refund                      11163 non-null  float64\n",
            " 31  check_in                    11163 non-null  float64\n",
            " 32  escalated_at                102 non-null    object \n",
            " 33  escalation_summary          102 non-null    object \n",
            " 34  escalation_whatsapp_url     102 non-null    object \n",
            " 35  platform                    4735 non-null   object \n",
            " 36  comments                    5 non-null      object \n",
            " 37  org_id                      16 non-null     object \n",
            " 38  display_id                  16 non-null     object \n",
            " 39  correlative_numeric         16 non-null     float64\n",
            " 40  lookup_policy_count         9 non-null      float64\n",
            "dtypes: float64(9), int64(7), object(25)\n",
            "memory usage: 3.6+ MB\n",
            "\n",
            "Head (3)\n",
            "                                    _id      thread_id client  source  user  \\\n",
            "0  {'$oid': '68e63abaff1df54379992d8f'}  1755721673370  avior  iframe  true   \n",
            "1  {'$oid': '68e63abaff1df54379992d93'}  1755722066769  avior  iframe  true   \n",
            "2  {'$oid': '68e63abaff1df54379992d95'}  1755722205882  avior  iframe  true   \n",
            "\n",
            "  status  get_user_info  check_pnr  lookup_policy  availability  \\\n",
            "0  ended              0          0              0             1   \n",
            "1  ended              0          0              0             0   \n",
            "2  ended              0          0              0             0   \n",
            "\n",
            "   best_flight_option  booking  escalate_conversation  \\\n",
            "0                   1        0                      0   \n",
            "1                   0        0                      1   \n",
            "2                   0        0                      0   \n",
            "\n",
            "                              created_at  \\\n",
            "0  {'$date': '2025-08-20T20:28:05.376Z'}   \n",
            "1  {'$date': '2025-08-20T20:36:28.318Z'}   \n",
            "2  {'$date': '2025-08-20T20:37:13.201Z'}   \n",
            "\n",
            "                              updated_at  check_flight_schedule  \\\n",
            "0  {'$date': '2026-01-29T19:58:52.888Z'}                    0.0   \n",
            "1  {'$date': '2025-08-20T20:39:11.649Z'}                    0.0   \n",
            "2  {'$date': '2025-08-20T20:37:16.311Z'}                    0.0   \n",
            "\n",
            "  correlative_id  ai_resolved ended_reason flags Checked_PNR  \\\n",
            "0      OP-000003          0.0      timeout    []         NaN   \n",
            "1      OP-000008          0.0    escalated   NaN         NaN   \n",
            "2      OP-000009          0.0      timeout   NaN         NaN   \n",
            "\n",
            "   end_conversation  pnr  is_guest email last_tool_used  \\\n",
            "0               NaN  NaN       NaN   NaN            NaN   \n",
            "1               NaN  NaN       NaN   NaN            NaN   \n",
            "2               NaN  NaN       NaN   NaN            NaN   \n",
            "\n",
            "  last_interaction_timestamp checked_pnrs  cancel_purchase Checked_pnrs  \\\n",
            "0                        NaN          NaN              NaN          NaN   \n",
            "1                        NaN          NaN              NaN          NaN   \n",
            "2                        NaN          NaN              NaN          NaN   \n",
            "\n",
            "   refund  check_in escalated_at escalation_summary escalation_whatsapp_url  \\\n",
            "0     NaN       NaN          NaN                NaN                     NaN   \n",
            "1     NaN       NaN          NaN                NaN                     NaN   \n",
            "2     NaN       NaN          NaN                NaN                     NaN   \n",
            "\n",
            "  platform comments org_id display_id  correlative_numeric  \\\n",
            "0      NaN      NaN    NaN        NaN                  NaN   \n",
            "1      NaN      NaN    NaN        NaN                  NaN   \n",
            "2      NaN      NaN    NaN        NaN                  NaN   \n",
            "\n",
            "   lookup_policy_count  \n",
            "0                  NaN  \n",
            "1                  NaN  \n",
            "2                  NaN  \n",
            "------------------------------------------------------------\n",
            "DATAFRAME: df_messages\n",
            "Dimensiones: (135848, 32)\n",
            "\n",
            "Columnas\n",
            "['_id', 'client', 'source', 'user', 'thread_id', 'message_id', 'order', 'type', 'content', 'name', 'departure_airport', 'arrival_airport', 'isRoundTrip', 'departureDate', 'returnDate', 'pnr', 'passengers', 'number_passenger', 'segments', 'ancillaries', 'taxes', 'station', 'checked_pnr', 'status', 'tool_calls', 'additional_kwargs', 'response_metadata ', 'invalid_tool_calls', 'metadata', 'created_at', 'createdAt', 'updatedAt']\n",
            "\n",
            "Resumen de tipos y nulos\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135848 entries, 0 to 135847\n",
            "Data columns (total 32 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   _id                 135848 non-null  object \n",
            " 1   client              135848 non-null  object \n",
            " 2   source              135848 non-null  object \n",
            " 3   user                135848 non-null  object \n",
            " 4   thread_id           135848 non-null  object \n",
            " 5   message_id          135848 non-null  object \n",
            " 6   order               126013 non-null  float64\n",
            " 7   type                135848 non-null  object \n",
            " 8   content             135848 non-null  object \n",
            " 9   name                38569 non-null   object \n",
            " 10  departure_airport   9422 non-null    object \n",
            " 11  arrival_airport     9422 non-null    object \n",
            " 12  isRoundTrip         9422 non-null    float64\n",
            " 13  departureDate       9422 non-null    object \n",
            " 14  returnDate          1439 non-null    object \n",
            " 15  pnr                 199 non-null     object \n",
            " 16  passengers          254 non-null     object \n",
            " 17  number_passenger    254 non-null     float64\n",
            " 18  segments            254 non-null     object \n",
            " 19  ancillaries         0 non-null       float64\n",
            " 20  taxes               199 non-null     object \n",
            " 21  station             199 non-null     object \n",
            " 22  checked_pnr         2239 non-null    object \n",
            " 23  status              27558 non-null   object \n",
            " 24  tool_calls          56151 non-null   object \n",
            " 25  additional_kwargs   126013 non-null  object \n",
            " 26  response_metadata   126013 non-null  object \n",
            " 27  invalid_tool_calls  56151 non-null   object \n",
            " 28  metadata            0 non-null       float64\n",
            " 29  created_at          135848 non-null  object \n",
            " 30  createdAt           1 non-null       object \n",
            " 31  updatedAt           1 non-null       object \n",
            "dtypes: float64(5), object(27)\n",
            "memory usage: 33.2+ MB\n",
            "\n",
            "Head (3)\n",
            "                                    _id client  source  user      thread_id  \\\n",
            "0  {'$oid': '68e63abcff1df54379992de6'}  avior  iframe  true  1755721904514   \n",
            "1  {'$oid': '68e63abcff1df54379992e04'}  avior  iframe  true  1755722080963   \n",
            "2  {'$oid': '68e63abcff1df54379992e07'}  avior  iframe  true  1755722080963   \n",
            "\n",
            "                                    message_id  order   type  \\\n",
            "0         0e6fcca3-8f20-4446-9896-27484fcaa722    5.0   tool   \n",
            "1         e1b7425a-dafc-43db-851b-d9eacc162aee    3.0  human   \n",
            "2  run--301018b7-737f-4a57-a6cc-a8a6a80da11b-0    6.0     ai   \n",
            "\n",
            "                                                                                                                   content  \\\n",
            "0  1. Most Relevant Chunk:\\n Vuelos Nacionales e Internacionales Menores de edad, de nacionalidad venezolana, en vuelos...   \n",
            "1                                                                                         Desde Bogotá el 29 de septiembre   \n",
            "2  Actualmente, no encontré vuelos disponibles desde Bogotá a Orlando para el 29 de septiembre. ¿Te gustaría que revise...   \n",
            "\n",
            "            name departure_airport arrival_airport  isRoundTrip departureDate  \\\n",
            "0  lookup_policy              None            None          NaN          None   \n",
            "1           None              None            None          NaN          None   \n",
            "2           None              None            None          NaN          None   \n",
            "\n",
            "  returnDate   pnr passengers  number_passenger segments  ancillaries taxes  \\\n",
            "0       None  None       None               NaN     None          NaN  None   \n",
            "1       None  None       None               NaN     None          NaN  None   \n",
            "2       None  None       None               NaN     None          NaN  None   \n",
            "\n",
            "  station checked_pnr   status tool_calls  additional_kwargs  \\\n",
            "0    None        None  success       None                 {}   \n",
            "1    None        None     None       None                 {}   \n",
            "2    None        None     None         []  {'refusal': None}   \n",
            "\n",
            "                                                                                                        response_metadata   \\\n",
            "0                                                                                                                       {}   \n",
            "1                                                                                                                       {}   \n",
            "2  {'token_usage': {'completion_tokens': 54, 'prompt_tokens': 1509, 'total_tokens': 1563, 'completion_tokens_details': ...   \n",
            "\n",
            "  invalid_tool_calls  metadata                             created_at  \\\n",
            "0               None       NaN  {'$date': '2025-08-20T20:33:06.400Z'}   \n",
            "1               None       NaN  {'$date': '2025-08-20T20:35:30.663Z'}   \n",
            "2                 []       NaN  {'$date': '2025-08-20T20:35:30.945Z'}   \n",
            "\n",
            "  createdAt updatedAt  \n",
            "0       NaN       NaN  \n",
            "1       NaN       NaN  \n",
            "2       NaN       NaN  \n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def cargar_datos(ruta_threads: Path, ruta_messages: Path) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    if not ruta_threads.exists() or not ruta_messages.exists():\n",
        "        raise FileNotFoundError(\"No se encuentran los archivos JSON.\")\n",
        "\n",
        "    logger.info(\"Cargando datos desde %s y %s ...\", ruta_threads, ruta_messages)\n",
        "\n",
        "    try:\n",
        "        df_threads = pd.read_json(ruta_threads)\n",
        "        df_messages = pd.read_json(ruta_messages)\n",
        "    except ValueError as exc:\n",
        "        raise DataValidationError(f\"JSON malformado o estructura incompatible: {exc}\") from exc\n",
        "\n",
        "    if df_threads.empty or df_messages.empty:\n",
        "        raise DataValidationError(\"Alguno de los JSON esta vacio.\")\n",
        "\n",
        "    logger.info(\n",
        "        \"Datos cargados: threads=%d filas, messages=%d filas\",\n",
        "        len(df_threads),\n",
        "        len(df_messages),\n",
        "    )\n",
        "    return df_threads, df_messages\n",
        "\n",
        "\n",
        "def mostrar_estructura(df: pd.DataFrame, nombre: str, head_rows: int = 3) -> None:\n",
        "    print(f\"DATAFRAME: {nombre}\")\n",
        "    print(f\"Dimensiones: {df.shape}\")\n",
        "    print(\"\\nColumnas\")\n",
        "    print(df.columns.tolist())\n",
        "    print(\"\\nResumen de tipos y nulos\")\n",
        "    df.info()\n",
        "    print(f\"\\nHead ({head_rows})\")\n",
        "    print(df.head(head_rows))\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "try:\n",
        "    df_threads, df_messages = cargar_datos(THREADS_PATH, MESSAGES_PATH)\n",
        "    mostrar_estructura(df_threads, \"df_threads\")\n",
        "    mostrar_estructura(df_messages, \"df_messages\")\n",
        "except (FileNotFoundError, DataValidationError) as exc:\n",
        "    logger.error(\"Error durante la carga: %s\", exc)\n",
        "except Exception as exc:\n",
        "    logger.error(\"Error inesperado en carga: %s\", exc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea8b51d1",
      "metadata": {},
      "source": [
        "## 3. EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6fdd76ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANALISIS DEL DATASET: df_threads\n",
            "Dimensiones: 11500 filas x 41 columnas\n",
            "Duplicados: 0 (0.00%)\n",
            "\n",
            "Top 15 columnas con faltantes\n",
            "                            missing_count\n",
            "comments                            11495\n",
            "lookup_policy_count                 11491\n",
            "org_id                              11484\n",
            "display_id                          11484\n",
            "correlative_numeric                 11484\n",
            "Checked_PNR                         11478\n",
            "escalated_at                        11398\n",
            "escalation_summary                  11398\n",
            "escalation_whatsapp_url             11398\n",
            "flags                               10850\n",
            "end_conversation                    10784\n",
            "Checked_pnrs                         8970\n",
            "platform                             6765\n",
            "last_tool_used                       1947\n",
            "last_interaction_timestamp            930\n",
            "\n",
            "Top 15 columnas con valores unicos\n",
            "                            unique_values\n",
            "_id                                 11500\n",
            "created_at                          11500\n",
            "correlative_id                      11500\n",
            "thread_id                           11350\n",
            "updated_at                          11286\n",
            "last_interaction_timestamp          10570\n",
            "email                                4822\n",
            "Checked_pnrs                         1741\n",
            "user                                 1506\n",
            "pnr                                   186\n",
            "escalation_whatsapp_url               102\n",
            "escalation_summary                    102\n",
            "escalated_at                          102\n",
            "availability                           33\n",
            "Checked_PNR                            18\n",
            "------------------------------------------------------------\n",
            "ANALISIS DEL DATASET: df_messages\n",
            "Dimensiones: 135848 filas x 32 columnas\n",
            "Duplicados: 0 (0.00%)\n",
            "\n",
            "Top 15 columnas con faltantes\n",
            "                   missing_count\n",
            "metadata                  135848\n",
            "ancillaries               135848\n",
            "updatedAt                 135847\n",
            "createdAt                 135847\n",
            "pnr                       135649\n",
            "station                   135649\n",
            "taxes                     135649\n",
            "segments                  135594\n",
            "passengers                135594\n",
            "number_passenger          135594\n",
            "returnDate                134409\n",
            "checked_pnr               133609\n",
            "isRoundTrip               126426\n",
            "departureDate             126426\n",
            "departure_airport         126426\n",
            "\n",
            "Top 15 columnas con valores unicos\n",
            "                    unique_values\n",
            "_id                        135848\n",
            "message_id                 135848\n",
            "created_at                 135848\n",
            "content                     72697\n",
            "response_metadata           56152\n",
            "tool_calls                  25642\n",
            "thread_id                   11268\n",
            "user                         1498\n",
            "checked_pnr                  1391\n",
            "departureDate                 490\n",
            "additional_kwargs             417\n",
            "returnDate                    291\n",
            "pnr                           200\n",
            "passengers                    182\n",
            "segments                      178\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def _get_hashable_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    temp_df = df.copy()\n",
        "    object_cols = temp_df.select_dtypes(include=[\"object\"]).columns\n",
        "    temp_df[object_cols] = temp_df[object_cols].astype(str).replace(\"nan\", pd.NA)\n",
        "    return temp_df\n",
        "\n",
        "\n",
        "def _profile_missing(df: pd.DataFrame, top_n: int = 15) -> pd.DataFrame:\n",
        "    missing = df.isna().sum().sort_values(ascending=False)\n",
        "    return missing[missing > 0].head(top_n).to_frame(name=\"missing_count\")\n",
        "\n",
        "    \n",
        "def _profile_uniques(df: pd.DataFrame, top_n: int = 15) -> pd.DataFrame:\n",
        "    safe_df = _get_hashable_df(df)\n",
        "    uniques = safe_df.nunique(dropna=True).sort_values(ascending=False).head(top_n)\n",
        "    return uniques.to_frame(name=\"unique_values\")\n",
        "\n",
        "\n",
        "def _safe_duplicated_count(df: pd.DataFrame) -> int:\n",
        "    safe_df = _get_hashable_df(df)\n",
        "    return safe_df.duplicated().sum()\n",
        "\n",
        "\n",
        "def analizar_dataset(df: pd.DataFrame, nombre: str) -> None:\n",
        "    print(f\"ANALISIS DEL DATASET: {nombre}\")\n",
        "    print(f\"Dimensiones: {df.shape[0]} filas x {df.shape[1]} columnas\")\n",
        "\n",
        "    n_duplicados = _safe_duplicated_count(df)\n",
        "    perc_duplicados = (n_duplicados / len(df)) * 100 if len(df) else 0\n",
        "    print(f\"Duplicados: {n_duplicados} ({perc_duplicados:.2f}%)\")\n",
        "\n",
        "    print(\"\\nTop 15 columnas con faltantes\")\n",
        "    missing_df = _profile_missing(df, top_n=15)\n",
        "    if missing_df.empty:\n",
        "        print(\"No hay valores faltantes.\")\n",
        "    else:\n",
        "        print(missing_df)\n",
        "\n",
        "    print(\"\\nTop 15 columnas con valores unicos\")\n",
        "    print(_profile_uniques(df, top_n=15))\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "analizar_dataset(df_threads, \"df_threads\")\n",
        "analizar_dataset(df_messages, \"df_messages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a8b7e5",
      "metadata": {},
      "source": [
        "## 4. Tabla maestra (ETL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cff2853d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:04,636 - aerya - WARNING - Merge: 207 threads sin mensajes fueron descartados (11500 -> 11293)\n",
            "2026-02-09 14:50:04,728 - aerya - INFO - Tabla maestra creada correctamente - Dimensiones: (11293, 46)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       thread_id  msg_count  duration_minutes\n",
            "0  1755721673370         11          1.954083\n",
            "1  1755722066769         13          2.671300\n",
            "2  1755722205882          3          0.004317\n"
          ]
        }
      ],
      "source": [
        "def _to_snake_case(name: str) -> str:\n",
        "    name = name.strip()\n",
        "    name = re.sub(r\"[\\s\\-]+\", \"_\", name)\n",
        "    name = re.sub(r\"[^0-9a-zA-Z_]+\", \"\", name)\n",
        "    name = re.sub(r\"_+\", \"_\", name)\n",
        "    return name.lower()\n",
        "\n",
        "#normalizar contenido de texto\n",
        "def _normalize_text_content(value: Any) -> str:\n",
        "    if value is None:\n",
        "        return \"\"\n",
        "    if isinstance(value, float) and pd.isna(value):\n",
        "        return \"\"\n",
        "    if isinstance(value, (list, tuple, set)):\n",
        "        return \"; \".join(str(item) for item in value)\n",
        "    if isinstance(value, dict):\n",
        "        return json.dumps(value, ensure_ascii=False)\n",
        "    return str(value).strip()\n",
        "\n",
        "#normalizar columnas\n",
        "def normalizar_columnas(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = [_to_snake_case(col) for col in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "#extraer fecha\n",
        "def _extract_date_value(value: Any) -> Optional[str]:\n",
        "    if isinstance(value, dict) and \"$date\" in value:\n",
        "        return value[\"$date\"]\n",
        "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
        "        return None\n",
        "    return str(value)\n",
        "\n",
        "\n",
        "#crear tabla maestra\n",
        "def crear_tabla_maestra(df_t: pd.DataFrame, df_m: pd.DataFrame) -> pd.DataFrame:\n",
        "    df_t = normalizar_columnas(df_t)\n",
        "    df_m = normalizar_columnas(df_m)\n",
        "\n",
        "    validar_columnas(df_t, {\"thread_id\"}, \"threads\")\n",
        "    validar_columnas(df_m, {\"thread_id\", \"content\"}, \"messages\")\n",
        "\n",
        "    if \"created_at\" in df_t.columns:\n",
        "        df_t[\"created_at\"] = pd.to_datetime(\n",
        "            df_t[\"created_at\"].map(_extract_date_value), errors=\"coerce\", utc=True\n",
        "        )\n",
        "\n",
        "    col_fecha_msg = \"created_at\" if \"created_at\" in df_m.columns else \"createdat\"\n",
        "    if col_fecha_msg in df_m.columns:\n",
        "        df_m[\"msg_timestamp\"] = pd.to_datetime(\n",
        "            df_m[col_fecha_msg].map(_extract_date_value), errors=\"coerce\", utc=True\n",
        "        )\n",
        "    else:\n",
        "        df_m[\"msg_timestamp\"] = pd.NaT\n",
        "\n",
        "    df_m = df_m.sort_values(by=[\"thread_id\", \"msg_timestamp\"])\n",
        "    df_m[\"clean_content\"] = df_m[\"content\"].apply(_normalize_text_content)\n",
        "\n",
        "    df_grouped = df_m.groupby(\"thread_id\").agg(\n",
        "        full_conversation=(\"clean_content\", lambda x: \" | \".join(x[x != \"\"])),\n",
        "        msg_count=(\"clean_content\", \"count\"),\n",
        "        first_msg=(\"msg_timestamp\", \"min\"),\n",
        "        last_msg=(\"msg_timestamp\", \"max\"),\n",
        "    ).reset_index()\n",
        "\n",
        "    if df_grouped.empty:\n",
        "        raise DataValidationError(\"No se pudieron agrupar mensajes por thread_id.\")\n",
        "\n",
        "    threads_antes = len(df_t)\n",
        "    df_master = pd.merge(df_t, df_grouped, on=\"thread_id\", how=\"inner\")\n",
        "    threads_perdidos = threads_antes - len(df_master)\n",
        "\n",
        "    if df_master.empty:\n",
        "        raise DataValidationError(\"La tabla maestra quedo vacia tras el merge.\")\n",
        "\n",
        "    if threads_perdidos > 0:\n",
        "        logger.warning(\n",
        "            \"Merge: %d threads sin mensajes fueron descartados (%d -> %d)\",\n",
        "            threads_perdidos, threads_antes, len(df_master),\n",
        "        )\n",
        "\n",
        "    df_master[\"duration_minutes\"] = (\n",
        "        (df_master[\"last_msg\"] - df_master[\"first_msg\"]).dt.total_seconds() / 60\n",
        "    ).fillna(0)\n",
        "\n",
        "    return df_master\n",
        "\n",
        "\n",
        "try:\n",
        "    df_master = crear_tabla_maestra(df_threads, df_messages)\n",
        "    logger.info(\"Tabla maestra creada correctamente - Dimensiones: %s\", df_master.shape)\n",
        "    print(df_master[[\"thread_id\", \"msg_count\", \"duration_minutes\"]].head(3))\n",
        "except DataValidationError as exc:\n",
        "    logger.error(\"Error de validacion en tabla maestra: %s\", exc)\n",
        "except Exception as exc:\n",
        "    logger.error(\"Error en la tabla maestra: %s\", exc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b736ae38",
      "metadata": {},
      "source": [
        "## 5. Graficas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "89254fbc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26596\\292121621.py:42: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  rate = tmp.groupby(\"msg_bucket\")[\"escalate_conversation\"].mean().reset_index()\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metricas de impacto (resumen)\n",
            "   tasa_escalamiento  duracion_promedio_min  duracion_p90_min  \\\n",
            "0           0.169043               5.864238           6.33049   \n",
            "\n",
            "   mensajes_promedio  mensajes_p90  \\\n",
            "0          12.078279          23.0   \n",
            "\n",
            "                                                      estado_top  \n",
            "0  {\"ended\": 11291, \"completed_user\": 1, \"completed_timeout\": 1}  \n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def _plot_escalamiento_por_categoria(df: pd.DataFrame, col: str, top_n: int = 10) -> None:\n",
        "    if col not in df.columns or \"escalate_conversation\" not in df.columns:\n",
        "        print(f\"No se puede graficar por {col}.\")\n",
        "        return\n",
        "\n",
        "    tmp = df[[col, \"escalate_conversation\"]].copy()\n",
        "    tmp[\"escalate_conversation\"] = tmp[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "\n",
        "    rate = (\n",
        "        tmp.groupby(col)[\"escalate_conversation\"]\n",
        "        .mean()\n",
        "        .sort_values(ascending=False)\n",
        "        .head(top_n)\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.barplot(data=rate, x=\"escalate_conversation\", y=col, color=\"#1f77b4\")\n",
        "    plt.title(f\"Tasa de escalamiento por {col} (top {top_n})\")\n",
        "    plt.xlabel(\"Tasa de escalamiento\")\n",
        "    plt.ylabel(col)\n",
        "    plt.xlim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def _plot_mensajes_vs_escalamiento(df: pd.DataFrame) -> None:\n",
        "    if \"msg_count\" not in df.columns or \"escalate_conversation\" not in df.columns:\n",
        "        print(\"No se puede graficar mensajes vs escalamiento.\")\n",
        "        return\n",
        "\n",
        "    tmp = df[[\"msg_count\", \"escalate_conversation\"]].copy()\n",
        "    tmp[\"escalate_conversation\"] = tmp[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "\n",
        "    bins = [0, 2, 5, 10, 20, 50, 100, np.inf]\n",
        "    labels = [\"0-2\", \"3-5\", \"6-10\", \"11-20\", \"21-50\", \"51-100\", \"100+\"]\n",
        "    tmp[\"msg_bucket\"] = pd.cut(tmp[\"msg_count\"], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "    rate = tmp.groupby(\"msg_bucket\")[\"escalate_conversation\"].mean().reset_index()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.barplot(data=rate, x=\"msg_bucket\", y=\"escalate_conversation\", color=\"#ff7f0e\")\n",
        "    plt.title(\"Tasa de escalamiento por volumen de mensajes\")\n",
        "    plt.xlabel(\"Mensajes por hilo\")\n",
        "    plt.ylabel(\"Tasa de escalamiento\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "_plot_escalamiento_por_categoria(df_master, \"status\", top_n=8)\n",
        "_plot_mensajes_vs_escalamiento(df_master)\n",
        "\n",
        "\n",
        "def metricas_impacto_aerolinea(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        raise DataValidationError(\"No hay datos para calcular metricas.\")\n",
        "\n",
        "    required = {\"escalate_conversation\", \"duration_minutes\", \"msg_count\", \"status\"}\n",
        "    available = required.intersection(df.columns)\n",
        "\n",
        "    metrics: Dict[str, Any] = {}\n",
        "    if \"escalate_conversation\" in available:\n",
        "        target = df[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "        metrics[\"tasa_escalamiento\"] = target.mean()\n",
        "\n",
        "    if \"duration_minutes\" in available:\n",
        "        metrics[\"duracion_promedio_min\"] = df[\"duration_minutes\"].mean()\n",
        "        metrics[\"duracion_p90_min\"] = df[\"duration_minutes\"].quantile(0.90)\n",
        "\n",
        "    if \"msg_count\" in available:\n",
        "        metrics[\"mensajes_promedio\"] = df[\"msg_count\"].mean()\n",
        "        metrics[\"mensajes_p90\"] = df[\"msg_count\"].quantile(0.90)\n",
        "\n",
        "    if \"status\" in available:\n",
        "        metrics[\"estado_top\"] = json.dumps(df[\"status\"].value_counts().head(5).to_dict())\n",
        "\n",
        "    metrics_df = pd.DataFrame([metrics])\n",
        "    print(\"Metricas de impacto (resumen)\")\n",
        "    print(metrics_df)\n",
        "    return metrics_df\n",
        "\n",
        "\n",
        "_ = metricas_impacto_aerolinea(df_master)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648701ac",
      "metadata": {},
      "source": [
        "## 6. Embeddings locales con Ollama + modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "198588de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:27,711 - aerya - INFO - Todos los chunks estaban en cache.\n",
            "2026-02-09 14:50:29,897 - aerya - INFO - Modelo guardado: models\\model_v1.joblib\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "REPORTE\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.83      0.90      1878\n",
            "           1       0.52      0.87      0.65       381\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.84      2259\n",
            "   macro avg       0.50      0.57      0.51      2259\n",
            "weighted avg       0.89      0.84      0.85      2259\n",
            "\n",
            "\n",
            "MATRIZ CONFUSION\n",
            "[[1567  307    4]\n",
            " [  51  330    0]\n",
            " [   0    0    0]]\n",
            "Falsos Negativos: 51\n",
            "ROC-AUC: 0.9317\n",
            "PR-AUC: 0.7980\n",
            "Costo Esperado: 562\n"
          ]
        }
      ],
      "source": [
        "import hashlib\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        ")\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "import warnings\n",
        "\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# CONFIGURACION\n",
        "EMBEDDINGS_CACHE_PATH = Path(\"outputs\") / \"embeddings_cache.parquet\"\n",
        "MODEL_DIR = Path(\"models\")\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "MAX_CHARS = 1000\n",
        "CHUNK_SIZE = 500\n",
        "\n",
        "\n",
        "# DATA PREPARATION\n",
        "def _preparar_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    required = {\"full_conversation\", \"escalate_conversation\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise DataValidationError(f\"Faltan columnas: {missing}\")\n",
        "\n",
        "    df_model = df.copy()\n",
        "\n",
        "    df_model[\"full_conversation\"] = (\n",
        "        df_model[\"full_conversation\"]\n",
        "        .fillna(\"\")\n",
        "        .str.slice(0, MAX_CHARS)\n",
        "    )\n",
        "\n",
        "    df_model = df_model[df_model[\"full_conversation\"].str.len() > 0]\n",
        "    df_model[\"target\"] = df_model[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "\n",
        "    return df_model\n",
        "\n",
        "\n",
        "# TEXT UTILS\n",
        "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE) -> List[str]:\n",
        "    words = text.split()\n",
        "    return [\n",
        "        \" \".join(words[i:i + chunk_size])\n",
        "        for i in range(0, len(words), chunk_size)\n",
        "    ]\n",
        "\n",
        "\n",
        "def _hash_text(text: str) -> str:\n",
        "    return hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "\n",
        "def _build_chunks_for_texts(texts: List[str]) -> Tuple[List[str], List[List[str]]]:\n",
        "    all_chunks: List[str] = []\n",
        "    text_to_hashes: List[List[str]] = []\n",
        "\n",
        "    for text in texts:\n",
        "        chunks = chunk_text(text)\n",
        "        hashes = [_hash_text(chunk) for chunk in chunks]\n",
        "        all_chunks.extend(chunks)\n",
        "        text_to_hashes.append(hashes)\n",
        "\n",
        "    return all_chunks, text_to_hashes\n",
        "\n",
        "\n",
        "# CACHE\n",
        "def _load_embeddings_cache(\n",
        "    path: Path = EMBEDDINGS_CACHE_PATH\n",
        ") -> Dict[str, List[float]]:\n",
        "\n",
        "    if not path.exists():\n",
        "        return {}\n",
        "\n",
        "    cache_df = pd.read_parquet(path)\n",
        "    return dict(zip(cache_df[\"text_hash\"], cache_df[\"embedding\"]))\n",
        "\n",
        "\n",
        "def _save_embeddings_cache(\n",
        "    cache: Dict[str, List[float]],\n",
        "    path: Path = EMBEDDINGS_CACHE_PATH\n",
        ") -> None:\n",
        "\n",
        "    cache_df = pd.DataFrame({\n",
        "        \"text_hash\": list(cache.keys()),\n",
        "        \"embedding\": list(cache.values())\n",
        "    })\n",
        "\n",
        "    path.parent.mkdir(exist_ok=True)\n",
        "    cache_df.to_parquet(path, index=False)\n",
        "    logger.info(\"Cache actualizado: %s\", path)\n",
        "\n",
        "\n",
        "# EMBEDDINGS CORE\n",
        "def _batch_iter(items: List[str], batch_size: int) -> Iterable[List[str]]:\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        yield items[i:i + batch_size]\n",
        "\n",
        "\n",
        "def generate_embeddings_with_cache(\n",
        "    texts: List[str],\n",
        "    model_name: str = \"nomic-embed-text\",\n",
        "    batch_size: int = 64,\n",
        ") -> List[List[float]]:\n",
        "\n",
        "    if not texts:\n",
        "        raise EmbeddingError(\"No hay textos para vectorizar.\")\n",
        "\n",
        "    embedder = OllamaEmbeddings(model=model_name)\n",
        "    cache = _load_embeddings_cache()\n",
        "\n",
        "    all_chunks, text_to_hashes = _build_chunks_for_texts(texts)\n",
        "    unique_chunks = {}\n",
        "    for chunk in all_chunks:\n",
        "        chunk_hash = _hash_text(chunk)\n",
        "        if chunk_hash not in unique_chunks and chunk_hash not in cache:\n",
        "            unique_chunks[chunk_hash] = chunk\n",
        "\n",
        "    missing_hashes = list(unique_chunks.keys())\n",
        "    missing_chunks = [unique_chunks[h] for h in missing_hashes]\n",
        "\n",
        "    if missing_chunks:\n",
        "        for batch in tqdm(\n",
        "            _batch_iter(missing_chunks, batch_size),\n",
        "            desc=\"Vectorizando chunks\",\n",
        "        ):\n",
        "            batch_embeddings = embedder.embed_documents(batch)\n",
        "            for chunk_text, emb in zip(batch, batch_embeddings):\n",
        "                cache[_hash_text(chunk_text)] = emb\n",
        "\n",
        "        _save_embeddings_cache(cache)\n",
        "    else:\n",
        "        logger.info(\"Todos los chunks estaban en cache.\")\n",
        "\n",
        "    embeddings: List[List[float]] = []\n",
        "    for hashes in text_to_hashes:\n",
        "        chunk_embs = [cache[h] for h in hashes]\n",
        "        embeddings.append(np.mean(chunk_embs, axis=0).tolist())\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "\n",
        "# ML con Logistic Regression\n",
        "def train_model(\n",
        "    X_train: List[List[float]],\n",
        "    y_train: pd.Series\n",
        ") -> LogisticRegression:\n",
        "\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        raise ModelTrainingError(\"Target con una sola clase.\")\n",
        "\n",
        "    clf = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    return clf\n",
        "\n",
        "\n",
        "def save_model(model: LogisticRegression, version: str = \"v1\") -> Path:\n",
        "    model_path = MODEL_DIR / f\"model_{version}.joblib\"\n",
        "    joblib.dump(model, model_path)\n",
        "    logger.info(\"Modelo guardado: %s\", model_path)\n",
        "    return model_path\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test) -> None:\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"\\nREPORTE\")\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "        print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"\\nMATRIZ CONFUSION\")\n",
        "    print(cm)\n",
        "    print(f\"Falsos Negativos: {cm[1][0]}\")\n",
        "\n",
        "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
        "    print(f\"PR-AUC: {average_precision_score(y_test, y_proba):.4f}\")\n",
        "\n",
        "    fn_cost = 5\n",
        "    fp_cost = 1\n",
        "    total_cost = cm[1][0]*fn_cost + cm[0][1]*fp_cost\n",
        "    print(f\"Costo Esperado: {total_cost}\")\n",
        "\n",
        "\n",
        "# PIPELINE\n",
        "def entrenar_clasificador_embeddings(\n",
        "    df: pd.DataFrame,\n",
        "    model_name: str = \"nomic-embed-text\"\n",
        "):\n",
        "\n",
        "    df_model = _preparar_dataset(df)\n",
        "\n",
        "    texts = df_model[\"full_conversation\"].tolist()\n",
        "\n",
        "    embeddings = generate_embeddings_with_cache(\n",
        "        texts,\n",
        "        model_name=model_name,\n",
        "        batch_size=64,\n",
        "    )\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        embeddings,\n",
        "        df_model[\"target\"],\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=df_model[\"target\"]\n",
        "    )\n",
        "\n",
        "    clf = train_model(X_train, y_train)\n",
        "    save_model(clf)\n",
        "\n",
        "    evaluate_model(clf, X_test, y_test)\n",
        "\n",
        "    return clf, X_test, y_test\n",
        "\n",
        "# RUN\n",
        "try:\n",
        "    clf_model, X_test, y_test = entrenar_clasificador_embeddings(df_master)\n",
        "except (EmbeddingError, ModelTrainingError, DataValidationError) as exc:\n",
        "    logger.error(\"Error controlado: %s\", exc)\n",
        "except Exception as exc:\n",
        "    logger.error(\"Error inesperado: %s\", exc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee8c3aaa",
      "metadata": {},
      "source": [
        "## 7. Agente LangGraph con OpenAI \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6596b6e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# \n",
        "# --- LLM Singleton ---\n",
        "LLM = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "def construir_resumen_contexto(df: pd.DataFrame) -> str:\n",
        "    resumen = []\n",
        "    if \"escalate_conversation\" in df.columns:\n",
        "        tasa = df[\"escalate_conversation\"].fillna(0).astype(int).mean()\n",
        "        resumen.append(f\"Tasa de escalamiento: {tasa:.3f}\")\n",
        "    if \"duration_minutes\" in df.columns:\n",
        "        resumen.append(f\"Duracion promedio (min): {df['duration_minutes'].mean():.2f}\")\n",
        "    if \"msg_count\" in df.columns:\n",
        "        resumen.append(f\"Mensajes promedio: {df['msg_count'].mean():.2f}\")\n",
        "    return \"\\n\".join(resumen)\n",
        "\n",
        "def construir_system_prompt(contexto: str) -> str:\n",
        "    return (\n",
        "        \"Rol: Analista de operaciones de una aerolinea.\\n\"\n",
        "        \"Objetivo: Responder preguntas de negocio con base en metricas.\\n\"\n",
        "        \"Restricciones: No revelar razonamiento interno. No usar emojis.\\n\"\n",
        "        \"Formato de salida: JSON con llaves summary, insights, risks, actions, metrics_used.\\n\"\n",
        "        \"Ejemplo de salida:\\n\"\n",
        "        \"{\\n\"\n",
        "        \"  \\\"summary\\\": \\\"La tasa de escalamiento es elevada en ciertos estados.\\\",\\n\"\n",
        "        \"  \\\"insights\\\": [\\\"Los hilos con mas mensajes muestran mayor escalamiento.\\\"],\\n\"\n",
        "        \"  \\\"risks\\\": [\\\"Falsos negativos impactan la satisfaccion del cliente.\\\"],\\n\"\n",
        "        \"  \\\"actions\\\": [\\\"Priorizar mejora en los estados con mayor tasa.\\\"],\\n\"\n",
        "        \"  \\\"metrics_used\\\": [\\\"tasa_escalamiento\\\", \\\"mensajes_promedio\\\"]\\n\"\n",
        "        \"}\\n\\n\"\n",
        "        f\"Contexto:\\n{contexto}\"\n",
        "    )\n",
        "\n",
        "def _safe_datetime_series(series: pd.Series) -> pd.Series:\n",
        "    if pd.api.types.is_datetime64_any_dtype(series):\n",
        "        return series\n",
        "    return pd.to_datetime(series.map(lambda x: x.get(\"$date\") if isinstance(x, dict) else x), errors=\"coerce\")\n",
        "\n",
        "\n",
        "def _get_conversation_text(df: pd.DataFrame, thread_id: Optional[str]) -> str:\n",
        "    if not thread_id or \"thread_id\" not in df.columns:\n",
        "        return \"\"\n",
        "\n",
        "    match = df[df[\"thread_id\"].astype(str) == str(thread_id)]\n",
        "    if match.empty:\n",
        "        return \"\"\n",
        "\n",
        "    if \"full_conversation\" in df.columns:\n",
        "        return str(match[\"full_conversation\"].iloc[0])\n",
        "\n",
        "    text_cols = [c for c in [\"content\", \"message_text\", \"text\", \"body\"] if c in df.columns]\n",
        "    if text_cols:\n",
        "        return \"\\n\".join(match[text_cols[0]].astype(str).tolist())\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "# --- CORRECCIÓN 2: Clausura (Closure) para Tools ---\n",
        "# Evita depender de una variable global 'df_master' inestable.\n",
        "def build_tools(df: pd.DataFrame):\n",
        "    \n",
        "    @tool\n",
        "    def obtener_metricas_resumen() -> str:\n",
        "        \"\"\"Devuelve un resumen de metricas clave de la aerolinea.\"\"\"\n",
        "        return construir_resumen_contexto(df)\n",
        "\n",
        "    @tool\n",
        "    def top_hilos_por_mensajes(n: int = 5) -> str:\n",
        "        \"\"\"Devuelve los top hilos con mas mensajes y su conteo.\"\"\"\n",
        "        if \"msg_count\" not in df.columns:\n",
        "            return \"No existe la columna msg_count.\"\n",
        "        top_df = df[[\"thread_id\", \"msg_count\"]].sort_values(\"msg_count\", ascending=False).head(n)\n",
        "        return top_df.to_string(index=False)\n",
        "\n",
        "    @tool\n",
        "    def top_hilos_por_duracion(n: int = 5) -> str:\n",
        "        \"\"\"Devuelve los top hilos con mayor duracion (min).\"\"\"\n",
        "        if \"duration_minutes\" not in df.columns:\n",
        "            return \"No existe la columna duration_minutes.\"\n",
        "        top_df = df[[\"thread_id\", \"duration_minutes\"]].sort_values(\n",
        "            \"duration_minutes\", ascending=False\n",
        "        ).head(n)\n",
        "        return top_df.to_string(index=False)\n",
        "\n",
        "    @tool\n",
        "    def tasa_escalamiento_por_categoria(col: str = \"status\", top_n: int = 8) -> str:\n",
        "        \"\"\"Calcula la tasa de escalamiento por categoria (status, platform, source).\"\"\"\n",
        "        if col not in df.columns or \"escalate_conversation\" not in df.columns:\n",
        "            return f\"No existe la columna {col} o escalate_conversation.\"\n",
        "        tmp = df[[col, \"escalate_conversation\"]].copy()\n",
        "        tmp[\"escalate_conversation\"] = tmp[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "        rate = (\n",
        "            tmp.groupby(col)[\"escalate_conversation\"]\n",
        "            .mean()\n",
        "            .sort_values(ascending=False)\n",
        "            .head(top_n)\n",
        "            .reset_index()\n",
        "        )\n",
        "        return rate.to_string(index=False)\n",
        "\n",
        "    @tool\n",
        "    def resumen_tiempos_operativos() -> str:\n",
        "        \"\"\"Devuelve estadisticas de duracion y volumen de mensajes.\"\"\"\n",
        "        if \"duration_minutes\" not in df.columns or \"msg_count\" not in df.columns:\n",
        "            return \"No existen columnas de duracion o mensajes.\"\n",
        "        stats: Dict[str, float] = {\n",
        "            \"duracion_promedio_min\": df[\"duration_minutes\"].mean(),\n",
        "            \"duracion_p90_min\": df[\"duration_minutes\"].quantile(0.90),\n",
        "            \"mensajes_promedio\": df[\"msg_count\"].mean(),\n",
        "            \"mensajes_p90\": df[\"msg_count\"].quantile(0.90),\n",
        "        }\n",
        "        return pd.DataFrame([stats]).to_string(index=False)\n",
        "\n",
        "    @tool\n",
        "    def tendencia_escalamiento_mensual() -> str:\n",
        "        \"\"\"Muestra la tendencia mensual de escalamiento.\"\"\"\n",
        "        if \"created_at\" not in df.columns or \"escalate_conversation\" not in df.columns:\n",
        "            return \"No existen columnas requeridas para tendencia mensual.\"\n",
        "        tmp = df[[\"created_at\", \"escalate_conversation\"]].copy()\n",
        "        tmp[\"created_at\"] = _safe_datetime_series(tmp[\"created_at\"])\n",
        "        tmp = tmp.dropna(subset=[\"created_at\"])\n",
        "        tmp[\"month\"] = tmp[\"created_at\"].dt.to_period(\"M\").astype(str)\n",
        "        tmp[\"escalate_conversation\"] = tmp[\"escalate_conversation\"].fillna(0).astype(int)\n",
        "        trend = tmp.groupby(\"month\")[\"escalate_conversation\"].mean().reset_index()\n",
        "        return trend.to_string(index=False)\n",
        "\n",
        "    @tool\n",
        "    def obtener_conversacion_por_thread(thread_id: str) -> str:\n",
        "        \"\"\"Devuelve la conversacion completa para un thread_id.\"\"\"\n",
        "        text = _get_conversation_text(df, thread_id)\n",
        "        if not text:\n",
        "            return \"No se encontro conversacion para ese thread_id.\"\n",
        "        return text\n",
        "\n",
        "    return [\n",
        "        obtener_metricas_resumen, top_hilos_por_mensajes, top_hilos_por_duracion,\n",
        "        tasa_escalamiento_por_categoria, resumen_tiempos_operativos, tendencia_escalamiento_mensual,\n",
        "        obtener_conversacion_por_thread\n",
        "    ]\n",
        "\n",
        "# Referencia al dataframe para los nodos del grafo (evita globals dispersos)\n",
        "_DF_REF: Optional[pd.DataFrame] = None\n",
        "\n",
        "# Inicializamos las tools usando el df_master (que debe existir en el notebook)\n",
        "# Si no existe, usamos una lista vacia para evitar error de definición\n",
        "try:\n",
        "    _DF_REF = df_master\n",
        "    TOOLS = build_tools(df_master)\n",
        "except NameError:\n",
        "    TOOLS = []\n",
        "\n",
        "LLM_WITH_TOOLS = LLM.bind_tools(TOOLS) if TOOLS else LLM\n",
        "\n",
        "MAX_TOOL_CALLS = 3\n",
        "\n",
        "# --- CORRECCIÓN 6: Tipado Fuerte ---\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], add_messages]\n",
        "    tool_calls_count: int\n",
        "    thread_id: Optional[str]\n",
        "    route: Optional[str]\n",
        "    analysis: Dict[str, str]\n",
        "\n",
        "def _parse_json_response(text: str) -> Dict[str, str]:\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except (json.JSONDecodeError, ValueError, TypeError):\n",
        "        return {}\n",
        "\n",
        "\n",
        "def nodo_router(state: AgentState) -> AgentState:\n",
        "    if \"messages\" not in state or not state[\"messages\"]:\n",
        "        raise ValueError(\"Estado invalido: messages vacio\")\n",
        "\n",
        "    thread_id = state.get(\"thread_id\")\n",
        "    conversation_text = _get_conversation_text(_DF_REF, thread_id) if _DF_REF is not None else \"\"\n",
        "\n",
        "    router_prompt = (\n",
        "        \"Rol: Analista de conversaciones automatizado.\\n\"\n",
        "        \"Tarea: Clasificar sentimiento y motivo, y decidir la ruta.\\n\"\n",
        "        \"Reglas de ruteo:\\n\"\n",
        "        \"- Si el sentimiento es negativo o hay queja fuerte: route = escalar\\n\"\n",
        "        \"- Si la consulta es tecnica: route = tecnico\\n\"\n",
        "        \"- Si la conversacion parece resuelta: route = resumen\\n\"\n",
        "        \"- Si no hay thread_id o conversacion: route = assistant\\n\"\n",
        "        \"Devuelve SOLO JSON con llaves: route, sentiment, motivo, rationale.\\n\"\n",
        "    )\n",
        "\n",
        "    last_user = state[\"messages\"][-1].content if hasattr(state[\"messages\"][-1], \"content\") else \"\"\n",
        "    router_input = (\n",
        "        f\"thread_id: {thread_id}\\n\"\n",
        "        f\"conversacion:\\n{conversation_text}\\n\\n\"\n",
        "        f\"pregunta_actual:\\n{last_user}\"\n",
        "    )\n",
        "\n",
        "    response = LLM.invoke([\n",
        "        SystemMessage(content=router_prompt),\n",
        "        HumanMessage(content=router_input),\n",
        "    ])\n",
        "\n",
        "    analysis = _parse_json_response(getattr(response, \"content\", \"\"))\n",
        "    route = analysis.get(\"route\", \"assistant\")\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [response],\n",
        "        \"tool_calls_count\": state.get(\"tool_calls_count\", 0),\n",
        "        \"thread_id\": thread_id,\n",
        "        \"route\": route,\n",
        "        \"analysis\": analysis,\n",
        "    }\n",
        "\n",
        "\n",
        "def nodo_escalar_humano(state: AgentState) -> AgentState:\n",
        "    analysis = state.get(\"analysis\", {})\n",
        "    thread_id = state.get(\"thread_id\")\n",
        "    conversation_text = _get_conversation_text(_DF_REF, thread_id) if _DF_REF is not None else \"\"\n",
        "\n",
        "    prompt = (\n",
        "        \"Rol: Analista de conversaciones automatizado.\\n\"\n",
        "        \"Tarea: Generar salida de escalamiento a humano.\\n\"\n",
        "        \"Devuelve SOLO JSON con llaves: action, sentiment, motivo, summary, next_steps.\\n\"\n",
        "        \"action debe ser 'escalar_humano'.\"\n",
        "    )\n",
        "\n",
        "    response = LLM.invoke([\n",
        "        SystemMessage(content=prompt),\n",
        "        HumanMessage(content=f\"analisis: {analysis}\\n\\nconversacion:\\n{conversation_text}\"),\n",
        "    ])\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [response],\n",
        "        \"tool_calls_count\": state.get(\"tool_calls_count\", 0),\n",
        "    }\n",
        "\n",
        "\n",
        "def nodo_respuesta_tecnica(state: AgentState) -> AgentState:\n",
        "    analysis = state.get(\"analysis\", {})\n",
        "    thread_id = state.get(\"thread_id\")\n",
        "    conversation_text = _get_conversation_text(_DF_REF, thread_id) if _DF_REF is not None else \"\"\n",
        "\n",
        "    prompt = (\n",
        "        \"Rol: Analista de conversaciones automatizado.\\n\"\n",
        "        \"Tarea: Generar borrador de respuesta tecnica.\\n\"\n",
        "        \"Devuelve SOLO JSON con llaves: action, sentiment, motivo, respuesta, assumptions.\\n\"\n",
        "        \"action debe ser 'borrador_tecnico'.\"\n",
        "    )\n",
        "\n",
        "    response = LLM.invoke([\n",
        "        SystemMessage(content=prompt),\n",
        "        HumanMessage(content=f\"analisis: {analysis}\\n\\nconversacion:\\n{conversation_text}\"),\n",
        "    ])\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [response],\n",
        "        \"tool_calls_count\": state.get(\"tool_calls_count\", 0),\n",
        "    }\n",
        "\n",
        "\n",
        "def nodo_resumen_resuelto(state: AgentState) -> AgentState:\n",
        "    analysis = state.get(\"analysis\", {})\n",
        "    thread_id = state.get(\"thread_id\")\n",
        "    conversation_text = _get_conversation_text(_DF_REF, thread_id) if _DF_REF is not None else \"\"\n",
        "\n",
        "    prompt = (\n",
        "        \"Rol: Analista de conversaciones automatizado.\\n\"\n",
        "        \"Tarea: Generar resumen final de conversacion resuelta.\\n\"\n",
        "        \"Devuelve SOLO JSON con llaves: action, sentiment, motivo, summary, resolution.\\n\"\n",
        "        \"action debe ser 'resumen'.\"\n",
        "    )\n",
        "\n",
        "    response = LLM.invoke([\n",
        "        SystemMessage(content=prompt),\n",
        "        HumanMessage(content=f\"analisis: {analysis}\\n\\nconversacion:\\n{conversation_text}\"),\n",
        "    ])\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [response],\n",
        "        \"tool_calls_count\": state.get(\"tool_calls_count\", 0),\n",
        "    }\n",
        "\n",
        "\n",
        "def nodo_asistente(state: AgentState) -> AgentState:\n",
        "    # --- CORRECCIÓN 3: Validación de Input ---\n",
        "    if \"messages\" not in state or not state[\"messages\"]:\n",
        "        raise ValueError(\"Estado invalido: messages vacio\")\n",
        "\n",
        "    try:\n",
        "        response = LLM_WITH_TOOLS.invoke(\n",
        "            state[\"messages\"] + [\n",
        "                SystemMessage(content=\"IMPORTANTE: Devuelve SOLO un JSON válido con las claves solicitadas.\")\n",
        "            ]\n",
        "        )\n",
        "    except Exception as exc:\n",
        "        # --- CORRECCIÓN 4: Logging ---\n",
        "        logger.error(f\"Error invocando LLM: {exc}\")\n",
        "        raise AgentError(f\"Fallo del LLM: {exc}\") from exc\n",
        "\n",
        "    tool_calls_count = state.get(\"tool_calls_count\", 0)\n",
        "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
        "        tool_calls_count += 1\n",
        "\n",
        "    return {\n",
        "        \"messages\": state[\"messages\"] + [response],\n",
        "        \"tool_calls_count\": tool_calls_count,\n",
        "        \"thread_id\": state.get(\"thread_id\"),\n",
        "        \"route\": state.get(\"route\"),\n",
        "        \"analysis\": state.get(\"analysis\", {}),\n",
        "    }\n",
        "\n",
        "def construir_grafo() -> StateGraph:\n",
        "    tools_node = ToolNode(TOOLS)\n",
        "\n",
        "    def route_after_router(state: AgentState) -> str:\n",
        "        \"\"\"Decide el siguiente nodo segun la ruta del router.\"\"\"\n",
        "        ruta = state.get(\"route\", \"assistant\")\n",
        "        if ruta == \"escalar\":\n",
        "            return \"escalar\"\n",
        "        if ruta == \"tecnico\":\n",
        "            return \"tecnico\"\n",
        "        if ruta == \"resumen\":\n",
        "            return \"resumen\"\n",
        "        return \"assistant\"\n",
        "\n",
        "    def route_after_assistant(state: AgentState):\n",
        "        \"\"\"Decide si el asistente necesita tools o termina.\"\"\"\n",
        "        if state.get(\"tool_calls_count\", 0) >= MAX_TOOL_CALLS:\n",
        "            return END\n",
        "\n",
        "        last_msg = state[\"messages\"][-1]\n",
        "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "            return \"tools\"\n",
        "        return END\n",
        "\n",
        "    graph = StateGraph(AgentState)\n",
        "\n",
        "    # Nodos\n",
        "    graph.add_node(\"router\", nodo_router)\n",
        "    graph.add_node(\"assistant\", nodo_asistente)\n",
        "    graph.add_node(\"tools\", tools_node)\n",
        "    graph.add_node(\"escalar\", nodo_escalar_humano)\n",
        "    graph.add_node(\"tecnico\", nodo_respuesta_tecnica)\n",
        "    graph.add_node(\"resumen\", nodo_resumen_resuelto)\n",
        "\n",
        "    # Entry point: el router analiza y decide la ruta\n",
        "    graph.set_entry_point(\"router\")\n",
        "\n",
        "    # Router -> ruta especializada o asistente general\n",
        "    graph.add_conditional_edges(\n",
        "        \"router\",\n",
        "        route_after_router,\n",
        "        {\n",
        "            \"escalar\": \"escalar\",\n",
        "            \"tecnico\": \"tecnico\",\n",
        "            \"resumen\": \"resumen\",\n",
        "            \"assistant\": \"assistant\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Nodos especializados -> END\n",
        "    graph.add_edge(\"escalar\", END)\n",
        "    graph.add_edge(\"tecnico\", END)\n",
        "    graph.add_edge(\"resumen\", END)\n",
        "\n",
        "    # Asistente general -> tools loop\n",
        "    graph.add_conditional_edges(\n",
        "        \"assistant\",\n",
        "        route_after_assistant,\n",
        "        {\"tools\": \"tools\", END: END},\n",
        "    )\n",
        "    graph.add_edge(\"tools\", \"assistant\")\n",
        "\n",
        "    return graph\n",
        "\n",
        "GRAPH_TEMPLATE = construir_grafo()\n",
        "AGENT_APPS: Dict[str, Any] = {}\n",
        "\n",
        "def get_agent_app(session_id: str):\n",
        "    if session_id not in AGENT_APPS:\n",
        "        AGENT_APPS[session_id] = GRAPH_TEMPLATE.compile(checkpointer=MemorySaver())\n",
        "    return AGENT_APPS[session_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "810afcc6",
      "metadata": {},
      "source": [
        "## 7.A Memoria semantica FAISS \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e537a56a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:33,184 - faiss.loader - INFO - Loading faiss with AVX512 support.\n",
            "2026-02-09 14:50:33,184 - faiss.loader - INFO - Could not load library with AVX512 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
            "2026-02-09 14:50:33,184 - faiss.loader - INFO - Loading faiss with AVX2 support.\n",
            "2026-02-09 14:50:33,393 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.\n",
            "2026-02-09 14:50:35,653 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "from memory.faiss_memory import FaissMemory\n",
        "\n",
        "logging.getLogger(\"faiss.loader\").setLevel(logging.WARNING)\n",
        "\n",
        "MEMORY_ENABLED = True\n",
        "MEMORY = None\n",
        "\n",
        "try:\n",
        "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
        "    MEMORY = FaissMemory(\n",
        "        index_path=Path(\"outputs\") / \"faiss.index\",\n",
        "        metadata_path=Path(\"outputs\") / \"faiss_metadata.json\",\n",
        "        embeddings=embeddings,\n",
        "    )\n",
        "except Exception as exc:\n",
        "    MEMORY_ENABLED = False\n",
        "    MEMORY = None\n",
        "    logger.warning(\"Memoria FAISS deshabilitada: %s\", exc)\n",
        "\n",
        "\n",
        "def get_semantic_context(query: str, k: int = 3) -> str:\n",
        "    \"\"\"Recupera contexto semantico relevante. Devuelve string listo para prompt.\"\"\"\n",
        "    if not MEMORY_ENABLED or MEMORY is None or not query:\n",
        "        return \"\"\n",
        "\n",
        "    hits = MEMORY.search(query, k=k)\n",
        "    if not hits:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\".join([f\"- {h['text']}\" for h in hits])\n",
        "\n",
        "\n",
        "def save_semantic_memory(\n",
        "    question: str,\n",
        "    answer: str,\n",
        "    thread_id: str | None = None,\n",
        "    session_id: str | None = None,\n",
        ") -> None:\n",
        "    \"\"\"Guarda un par pregunta-respuesta en memoria semantica.\"\"\"\n",
        "    if not MEMORY_ENABLED or MEMORY is None or not answer:\n",
        "        return\n",
        "\n",
        "    MEMORY.save(\n",
        "        text=f\"Pregunta: {question}\\nRespuesta: {answer}\",\n",
        "        metadata={\"thread_id\": thread_id, \"session_id\": session_id},\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a0f3d4",
      "metadata": {},
      "source": [
        "## 8. Ejecucion del agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3108b0c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:35,864 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando flujo del agente...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:37,738 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Respuesta:\n",
            "```json\n",
            "{\n",
            "  \"route\": \"assistant\",\n",
            "  \"sentiment\": \"neutral\",\n",
            "  \"motivo\": \"consulta sobre tasas de escalamiento y duración de hilos\",\n",
            "  \"rationale\": \"La conversación no presenta quejas ni problemas técnicos, y la pregunta actual es informativa.\"\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:39,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agente solicita herramientas:\n",
            "  - tasa_escalamiento_por_categoria\n",
            "  - top_hilos_por_duracion\n",
            "\n",
            "Respuesta:\n",
            "               thread_id  duration_minutes\n",
            "           1762697576971       7362.599533\n",
            "6974d4f5d52e9d1dd1205fce       4066.875917\n",
            "6974d4f5d52e9d1dd1205fce       4066.875917\n",
            "6974d4f5d52e9d1dd1205fce       4066.875917\n",
            "6974d4f5d52e9d1dd1205fce       4066.875917\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:41,934 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Respuesta:\n",
            "{\n",
            "  \"summary\": \"La tasa de escalamiento por estado muestra que el estado 'ended' tiene una tasa de 0.169, mientras que otros estados no presentan escalamiento.\",\n",
            "  \"insights\": [\"El estado 'ended' es el único con tasa de escalamiento significativa.\", \"Los hilos con mayor duración tienen tiempos de 7362.60 minutos y 4066.88 minutos.\"],\n",
            "  \"risks\": [\"La falta de escalamiento en otros estados puede indicar problemas operativos.\"],\n",
            "  \"actions\": [\"Analizar las causas del escalamiento en el estado 'ended'.\", \"Investigar los hilos de mayor duración para identificar oportunidades de mejora.\"],\n",
            "  \"metrics_used\": [\"tasa_escalamiento\", \"duracion_hilos\"]\n",
            "}\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:42,513 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    if \"df_master\" not in globals():\n",
        "        if \"df_threads\" in globals() and \"df_messages\" in globals():\n",
        "            df_master = crear_tabla_maestra(df_threads, df_messages)\n",
        "        else:\n",
        "            df_master_path = Path(\"outputs\") / \"df_master.parquet\"\n",
        "            if df_master_path.exists():\n",
        "                df_master = pd.read_parquet(df_master_path)\n",
        "            else:\n",
        "                raise DataValidationError(\n",
        "                    \"df_master no esta cargado. Ejecuta la seccion de tabla maestra primero.\"\n",
        "                )\n",
        "\n",
        "    contexto = construir_resumen_contexto(df_master)\n",
        "    system_prompt = construir_system_prompt(contexto)\n",
        "\n",
        "    session_id = \"aerya-demo\"\n",
        "    app = get_agent_app(session_id)\n",
        "\n",
        "    thread_id = None\n",
        "    if \"thread_id\" in df_master.columns and not df_master.empty:\n",
        "        thread_id = str(df_master[\"thread_id\"].iloc[0])\n",
        "\n",
        "    user_question = \"Cual es la tasa de escalamiento por estado y cuales son los hilos con mayor duracion?\"\n",
        "\n",
        "    semantic_context = get_semantic_context(user_question, k=3)\n",
        "    if semantic_context:\n",
        "        system_prompt = f\"{system_prompt}\\n\\nContexto semantico relevante:\\n{semantic_context}\"\n",
        "\n",
        "    print(\"Iniciando flujo del agente...\")\n",
        "    for event in app.stream(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                SystemMessage(content=system_prompt),\n",
        "                HumanMessage(content=user_question),\n",
        "            ],\n",
        "            \"tool_calls_count\": 0,\n",
        "            \"thread_id\": thread_id,\n",
        "            \"route\": None,\n",
        "            \"analysis\": {},\n",
        "        },\n",
        "        config={\"configurable\": {\"thread_id\": session_id}, \"recursion_limit\": 6},\n",
        "    ):\n",
        "        for value in event.values():\n",
        "            if \"messages\" in value:\n",
        "                last_msg = value[\"messages\"][-1]\n",
        "                if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
        "                    print(\"\\nAgente solicita herramientas:\")\n",
        "                    for tool_call in last_msg.tool_calls:\n",
        "                        print(f\"  - {tool_call['name']}\")\n",
        "                elif hasattr(last_msg, \"content\") and last_msg.content:\n",
        "                    if last_msg.content.strip():\n",
        "                        print(\"\\nRespuesta:\")\n",
        "                        print(last_msg.content)\n",
        "\n",
        "                        try:\n",
        "                            json.loads(last_msg.content)\n",
        "                            save_semantic_memory(\n",
        "                                question=user_question,\n",
        "                                answer=last_msg.content,\n",
        "                                thread_id=thread_id,\n",
        "                                session_id=session_id,\n",
        "                            )\n",
        "                        except (json.JSONDecodeError, ValueError):\n",
        "                            logger.debug(\"Respuesta no es JSON valido, no se guarda en memoria.\")\n",
        "\n",
        "except AgentError as exc:\n",
        "    logger.error(\"Error en el agente: %s\", exc)\n",
        "    fallback = {\n",
        "        \"summary\": \"No fue posible consultar el agente en este momento.\",\n",
        "        \"insights\": [],\n",
        "        \"risks\": [\"La respuesta se entrega en modo degradado.\"],\n",
        "        \"actions\": [\"Reintentar la consulta o validar la clave de API.\"],\n",
        "        \"metrics_used\": [],\n",
        "    }\n",
        "    print(\"Fallback JSON:\")\n",
        "    print(json.dumps(fallback, indent=2, ensure_ascii=False))\n",
        "except Exception as exc:\n",
        "    logger.error(\"Error inesperado en el agente: %s\", exc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590ea9de",
      "metadata": {},
      "source": [
        "## 8.1 Evaluacion de calidad del agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1f0e6d3f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:43,586 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:45,214 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:46,581 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:48,489 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:49,923 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:51,255 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-09 14:50:53,114 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Response Quality Check n\n",
            "                                              pregunta  json_valido  score_estructura  tiempo_s\n",
            "                 Que factores afectan el escalamiento?         True               1.0      2.66\n",
            "   Cual es la duracion promedio de las conversaciones?         True               1.0      3.28\n",
            "Cuales son los estados con mayor tasa de escalamiento?         True               1.0      4.61\n",
            "\n",
            "Score promedio de estructura: 100%\n",
            "Respuestas JSON validas: 3/3\n",
            "Tiempo promedio: 3.5s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import uuid\n",
        "\n",
        "\n",
        "EXPECTED_KEYS = {\"summary\", \"insights\", \"risks\", \"actions\", \"metrics_used\"}\n",
        "\n",
        "_JSON_REGEX = re.compile(r\"\\{[\\s\\S]*\\}\")\n",
        "\n",
        "\n",
        "def _extract_json(text: str) -> Optional[str]:\n",
        "    \"\"\"Extrae el primer bloque JSON de un texto, incluso si tiene texto alrededor.\"\"\"\n",
        "    match = _JSON_REGEX.search(text)\n",
        "    return match.group(0) if match else None\n",
        "\n",
        "\n",
        "def evaluar_respuesta_agente(raw_response: str) -> Dict[str, Any]:\n",
        "    \"\"\"Evalua la calidad de una respuesta del agente.\"\"\"\n",
        "    result: Dict[str, Any] = {\n",
        "        \"json_valido\": False,\n",
        "        \"claves_presentes\": [],\n",
        "        \"claves_faltantes\": [],\n",
        "        \"score_estructura\": 0.0,\n",
        "        \"insights_no_vacios\": False,\n",
        "        \"actions_no_vacios\": False,\n",
        "    }\n",
        "\n",
        "    json_str = _extract_json(raw_response) if raw_response else None\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(json_str) if json_str else json.loads(raw_response)\n",
        "        result[\"json_valido\"] = True\n",
        "    except (json.JSONDecodeError, ValueError, TypeError):\n",
        "        result[\"claves_faltantes\"] = list(EXPECTED_KEYS)\n",
        "        return result\n",
        "\n",
        "    presentes = EXPECTED_KEYS.intersection(parsed.keys())\n",
        "    faltantes = EXPECTED_KEYS - presentes\n",
        "\n",
        "    result[\"claves_presentes\"] = sorted(presentes)\n",
        "    result[\"claves_faltantes\"] = sorted(faltantes)\n",
        "    result[\"score_estructura\"] = len(presentes) / len(EXPECTED_KEYS)\n",
        "\n",
        "    if \"insights\" in parsed and isinstance(parsed[\"insights\"], list):\n",
        "        result[\"insights_no_vacios\"] = len(parsed[\"insights\"]) > 0\n",
        "\n",
        "    if \"actions\" in parsed and isinstance(parsed[\"actions\"], list):\n",
        "        result[\"actions_no_vacios\"] = len(parsed[\"actions\"]) > 0\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def ejecutar_evaluacion_agente(\n",
        "    preguntas: List[str],\n",
        "    df: pd.DataFrame,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Ejecuta multiples preguntas en sesiones aisladas y evalua las respuestas.\"\"\"\n",
        "    resultados = []\n",
        "\n",
        "    contexto = construir_resumen_contexto(df)\n",
        "    system_prompt = construir_system_prompt(contexto)\n",
        "\n",
        "    for pregunta in preguntas:\n",
        "        eval_session = f\"eval-{uuid.uuid4().hex[:8]}\"\n",
        "        eval_app = get_agent_app(eval_session)\n",
        "\n",
        "        t0 = time.time()\n",
        "        try:\n",
        "            res = eval_app.invoke(\n",
        "                {\n",
        "                    \"messages\": [\n",
        "                        SystemMessage(content=system_prompt),\n",
        "                        HumanMessage(content=pregunta),\n",
        "                    ],\n",
        "                    \"tool_calls_count\": 0,\n",
        "                    \"thread_id\": None,\n",
        "                    \"route\": None,\n",
        "                    \"analysis\": {},\n",
        "                },\n",
        "                config={\"configurable\": {\"thread_id\": eval_session}, \"recursion_limit\": 6},\n",
        "            )\n",
        "            answer = res[\"messages\"][-1].content\n",
        "        except Exception as exc:\n",
        "            answer = str(exc)\n",
        "\n",
        "        elapsed = time.time() - t0\n",
        "        evaluacion = evaluar_respuesta_agente(answer)\n",
        "        evaluacion[\"pregunta\"] = pregunta[:80]\n",
        "        evaluacion[\"tiempo_s\"] = round(elapsed, 2)\n",
        "        resultados.append(evaluacion)\n",
        "\n",
        "    return pd.DataFrame(resultados)\n",
        "\n",
        "\n",
        "# --- Ejecucion ---\n",
        "\n",
        "PREGUNTAS_EVAL = [\n",
        "    \"Que factores afectan el escalamiento?\",\n",
        "    \"Cual es la duracion promedio de las conversaciones?\",\n",
        "    \"Cuales son los estados con mayor tasa de escalamiento?\",\n",
        "]\n",
        "\n",
        "try:\n",
        "    df_eval = ejecutar_evaluacion_agente(PREGUNTAS_EVAL, df_master)\n",
        "\n",
        "    print(\"Agent Response Quality Check n\")\n",
        "    print(df_eval[[\"pregunta\", \"json_valido\", \"score_estructura\", \"tiempo_s\"]].to_string(index=False))\n",
        "    print(f\"\\nScore promedio de estructura: {df_eval['score_estructura'].mean():.0%}\")\n",
        "    print(f\"Respuestas JSON validas: {df_eval['json_valido'].sum()}/{len(df_eval)}\")\n",
        "    print(f\"Tiempo promedio: {df_eval['tiempo_s'].mean():.1f}s\")\n",
        "except Exception as exc:\n",
        "    logger.error(\"Error en evaluacion del agente: %s\", exc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f60d500",
      "metadata": {},
      "source": [
        "## 9. Persistencia opcional de resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c7302a9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_DIR = Path(\"outputs\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "DF_MASTER_PATH = OUTPUT_DIR / \"df_master.parquet\"\n",
        "\n",
        "\n",
        "def cargar_df_master_si_existe(path: Path = DF_MASTER_PATH) -> pd.DataFrame | None:\n",
        "    if path.exists():\n",
        "        logger.info(\"Cargando desde: %s\", path)\n",
        "        return pd.read_parquet(path)\n",
        "    return None\n",
        "\n",
        "\n",
        "def obtener_df_master(\n",
        "    df_t: pd.DataFrame,\n",
        "    df_m: pd.DataFrame,\n",
        "    force_rebuild: bool = False,\n",
        "    persist: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    if not force_rebuild:\n",
        "        cached = cargar_df_master_si_existe()\n",
        "        if cached is not None:\n",
        "            return cached\n",
        "\n",
        "    df_master_local = crear_tabla_maestra(df_t, df_m)\n",
        "    if persist:\n",
        "        df_master_local.to_parquet(DF_MASTER_PATH, index=False)\n",
        "        logger.info(\"Guardado: %s\", DF_MASTER_PATH)\n",
        "    return df_master_local\n",
        "\n",
        "\n",
        "def guardar_metricas(df: pd.DataFrame, path_dir: Path = OUTPUT_DIR) -> None:\n",
        "    metrics_df = metricas_impacto_aerolinea(df)\n",
        "    metrics_df.to_csv(path_dir / \"metricas_impacto.csv\", index=False)\n",
        "    logger.info(\"Guardado: %s\", path_dir / \"metricas_impacto.csv\")\n",
        "\n",
        "\n",
        "def guardar_embeddings(df_embeddings: pd.DataFrame, path_dir: Path = OUTPUT_DIR) -> None:\n",
        "    df_embeddings.to_parquet(path_dir / \"df_embeddings.parquet\", index=False)\n",
        "    logger.info(\"Guardado: %s\", path_dir / \"df_embeddings.parquet\")\n",
        "\n",
        "\n",
        "# Uso recomendado:\n",
        "# df_master = obtener_df_master(df_threads, df_messages, force_rebuild=False, persist=False)\n",
        "# guardar_metricas(df_master)\n",
        "# guardar_embeddings(df_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ed1d15",
      "metadata": {},
      "source": [
        "## 10. API REST (FastAPI) - servicio en la nube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a11f9e9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-09 14:50:54,358 - aerya - WARNING - AERYA_API_KEY no definida. Usando key de desarrollo.\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "import signal\n",
        "from contextlib import contextmanager\n",
        "\n",
        "from fastapi import FastAPI, Header, HTTPException, Request\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, ConfigDict, Field\n",
        "from slowapi import Limiter\n",
        "from slowapi.util import get_remote_address\n",
        "from slowapi.errors import RateLimitExceeded\n",
        "from slowapi.middleware import SlowAPIMiddleware\n",
        "\n",
        "\n",
        "# --- Config ---\n",
        "\n",
        "API_KEY = os.environ.get(\"AERYA_API_KEY\")\n",
        "if not API_KEY:\n",
        "    logger.warning(\"AERYA_API_KEY no definida. Usando key de desarrollo.\")\n",
        "    API_KEY = \"dev-key-local\"\n",
        "\n",
        "MAX_QUESTION_LENGTH = 2000\n",
        "AGENT_TIMEOUT_S = 30\n",
        "\n",
        "\n",
        "# --- Modelos Pydantic ---\n",
        "\n",
        "class AskRequest(BaseModel):\n",
        "    question: str = Field(..., min_length=1, max_length=MAX_QUESTION_LENGTH)\n",
        "    session_id: str | None = Field(None, max_length=128)\n",
        "    thread_id: str | None = None\n",
        "\n",
        "\n",
        "class AskResponse(BaseModel):\n",
        "    answer: str\n",
        "    session_id: str\n",
        "\n",
        "\n",
        "class HealthResponse(BaseModel):\n",
        "    status: str\n",
        "    graph_loaded: bool\n",
        "    memory_enabled: bool\n",
        "    llm_reachable: bool\n",
        "    active_sessions: int\n",
        "\n",
        "\n",
        "class MetricsResponse(BaseModel):\n",
        "    model_config = ConfigDict(extra=\"allow\")\n",
        "\n",
        "\n",
        "class ErrorResponse(BaseModel):\n",
        "    error: str\n",
        "\n",
        "\n",
        "# --- App ---\n",
        "\n",
        "limiter = Limiter(key_func=get_remote_address)\n",
        "\n",
        "api = FastAPI(\n",
        "    title=\"Aerya REST API\",\n",
        "    description=(\n",
        "        \"API REST para el agente de analisis de conversaciones de la aerolinea.\\n\\n\"\n",
        "        \"**Autenticacion**: Header X-API-Key requerido en endpoints protegidos.\\n\\n\"\n",
        "        \"**Rate Limit**: 10 requests/minuto por cliente en /v1/agent/query.\"\n",
        "    ),\n",
        "    version=\"1.0.0\",\n",
        ")\n",
        "\n",
        "api.state.limiter = limiter\n",
        "api.add_middleware(SlowAPIMiddleware)\n",
        "api.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "\n",
        "# --- Timeout helper ---\n",
        "\n",
        "class AgentTimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def timeout(seconds: int):\n",
        "    \"\"\"Timeout context manager (solo Unix). En Windows se usa como fallback sin efecto.\"\"\"\n",
        "    if hasattr(signal, \"SIGALRM\"):\n",
        "        def handler(signum, frame):\n",
        "            raise AgentTimeoutError(f\"El agente excedio el timeout de {seconds}s.\")\n",
        "        old = signal.signal(signal.SIGALRM, handler)\n",
        "        signal.alarm(seconds)\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            signal.alarm(0)\n",
        "            signal.signal(signal.SIGALRM, old)\n",
        "    else:\n",
        "        yield\n",
        "\n",
        "\n",
        "# --- Dependencia: validacion de API key ---\n",
        "\n",
        "def validate_api_key(x_api_key: str = Header(..., alias=\"X-API-Key\")) -> str:\n",
        "    if x_api_key != API_KEY:\n",
        "        raise HTTPException(status_code=401, detail=\"API key invalida o ausente.\")\n",
        "    return x_api_key\n",
        "\n",
        "\n",
        "# --- Endpoints (versionado /v1) ---\n",
        "\n",
        "@api.get(\n",
        "    \"/v1/health\",\n",
        "    response_model=HealthResponse,\n",
        "    tags=[\"System\"],\n",
        "    summary=\"Diagnostico del sistema\",\n",
        "    responses={200: {\"description\": \"Estado actual de todos los componentes\"}},\n",
        ")\n",
        "def health_check():\n",
        "    llm_ok = True\n",
        "    try:\n",
        "        LLM.invoke(\"ping\")\n",
        "    except Exception:\n",
        "        llm_ok = False\n",
        "\n",
        "    return HealthResponse(\n",
        "        status=\"ok\" if llm_ok else \"degraded\",\n",
        "        graph_loaded=GRAPH_TEMPLATE is not None,\n",
        "        memory_enabled=MEMORY_ENABLED,\n",
        "        llm_reachable=llm_ok,\n",
        "        active_sessions=len(AGENT_APPS),\n",
        "    )\n",
        "\n",
        "\n",
        "@api.get(\n",
        "    \"/v1/metrics\",\n",
        "    response_model=MetricsResponse,\n",
        "    tags=[\"Analytics\"],\n",
        "    summary=\"Metricas de negocio de la aerolinea\",\n",
        "    responses={\n",
        "        401: {\"model\": ErrorResponse, \"description\": \"API key invalida\"},\n",
        "        500: {\"model\": ErrorResponse, \"description\": \"Error interno\"},\n",
        "    },\n",
        ")\n",
        "def get_metrics(x_api_key: str = Header(..., alias=\"X-API-Key\")):\n",
        "    validate_api_key(x_api_key)\n",
        "    try:\n",
        "        metrics_df = metricas_impacto_aerolinea(df_master)\n",
        "        return metrics_df.to_dict(orient=\"records\")[0]\n",
        "    except Exception as exc:\n",
        "        logger.error(\"Error en /v1/metrics: %s\", exc)\n",
        "        raise HTTPException(status_code=500, detail=str(exc))\n",
        "\n",
        "\n",
        "@api.post(\n",
        "    \"/v1/agent/query\",\n",
        "    response_model=AskResponse,\n",
        "    tags=[\"Agent\"],\n",
        "    summary=\"Consultar al agente de IA\",\n",
        "    responses={\n",
        "        401: {\"model\": ErrorResponse, \"description\": \"API key invalida\"},\n",
        "        429: {\"model\": ErrorResponse, \"description\": \"Rate limit excedido\"},\n",
        "        504: {\"model\": ErrorResponse, \"description\": \"Timeout del agente\"},\n",
        "        500: {\"model\": ErrorResponse, \"description\": \"Error interno\"},\n",
        "    },\n",
        ")\n",
        "@limiter.limit(\"10/minute\")\n",
        "def agent_query(request: Request, req: AskRequest, x_api_key: str = Header(..., alias=\"X-API-Key\")):\n",
        "    validate_api_key(x_api_key)\n",
        "\n",
        "    session_id = req.session_id or str(uuid.uuid4())\n",
        "\n",
        "    logger.info(\n",
        "        \"agent_request\",\n",
        "        extra={\"session_id\": session_id, \"thread_id\": req.thread_id},\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        contexto = construir_resumen_contexto(df_master)\n",
        "        system_prompt = construir_system_prompt(contexto)\n",
        "\n",
        "        semantic_context = get_semantic_context(req.question, k=3)\n",
        "        if semantic_context:\n",
        "            system_prompt = f\"{system_prompt}\\n\\nContexto semantico relevante:\\n{semantic_context}\"\n",
        "\n",
        "        app_graph = get_agent_app(session_id)\n",
        "\n",
        "        with timeout(AGENT_TIMEOUT_S):\n",
        "            result = app_graph.invoke(\n",
        "                {\n",
        "                    \"messages\": [\n",
        "                        SystemMessage(content=system_prompt),\n",
        "                        HumanMessage(content=req.question),\n",
        "                    ],\n",
        "                    \"tool_calls_count\": 0,\n",
        "                    \"thread_id\": req.thread_id,\n",
        "                    \"route\": None,\n",
        "                    \"analysis\": {},\n",
        "                },\n",
        "                config={\"configurable\": {\"thread_id\": session_id}, \"recursion_limit\": 6},\n",
        "            )\n",
        "\n",
        "        answer = result[\"messages\"][-1].content\n",
        "\n",
        "        try:\n",
        "            json.loads(answer)\n",
        "            save_semantic_memory(\n",
        "                question=req.question,\n",
        "                answer=answer,\n",
        "                thread_id=req.thread_id,\n",
        "                session_id=session_id,\n",
        "            )\n",
        "        except (json.JSONDecodeError, ValueError):\n",
        "            logger.debug(\"Respuesta no es JSON valido, no se guarda en memoria.\")\n",
        "\n",
        "        logger.info(\n",
        "            \"agent_response\",\n",
        "            extra={\"session_id\": session_id, \"answer_length\": len(answer)},\n",
        "        )\n",
        "\n",
        "        return AskResponse(answer=answer, session_id=session_id)\n",
        "\n",
        "    except AgentTimeoutError:\n",
        "        logger.warning(\"Timeout en /v1/agent/query session=%s\", session_id)\n",
        "        raise HTTPException(status_code=504, detail=f\"El agente excedio el timeout de {AGENT_TIMEOUT_S}s.\")\n",
        "\n",
        "    except Exception as exc:\n",
        "        logger.error(\"Error en /v1/agent/query session=%s: %s\", session_id, exc)\n",
        "        raise HTTPException(status_code=500, detail=str(exc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f49951a1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e8ff4413",
      "metadata": {},
      "source": [
        "## 12. Servidor local (demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "53a741d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [26596]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API activa en: http://localhost:8000/docs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [26596]\n"
          ]
        }
      ],
      "source": [
        "import uvicorn\n",
        "\n",
        "config = uvicorn.Config(api, host=\"0.0.0.0\", port=8000)\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "print(\"API activa en: http://localhost:8000/docs\")\n",
        "await server.serve()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Mioti)",
      "language": "python",
      "name": "mioti"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
